{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9afaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path to src directory (works on all platforms)\n",
    "src_dir = Path(__file__).parent.parent / \"src\" if hasattr(Path, '__file__') else Path.cwd().parent / \"src\"\n",
    "sys.path.insert(0, str(src_dir.resolve()))\n",
    "\n",
    "\n",
    "from config import ModelConfig, LoRAConfig, TrainingConfig, DataConfig\n",
    "from dataset import VLMJsonlDataset, make_collate_fn\n",
    "from modeling import setup_model_and_processor\n",
    "from trainer import VLMTrainer\n",
    "from utils import set_seeds, setup_logging, safe_makedirs, load_checkpoint_if_any\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# Setup logging\n",
    "setup_logging(\"../logs/training.log\")\n",
    "\n",
    "# Print environment info\n",
    "print(\"✓ Imports loaded\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c8425",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Configuration\n",
    "# EDIT THESE VALUES FOR YOUR EXPERIMENT\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# CHANGE THESE PATHS FOR YOUR ENVIRONMENT\n",
    "# ============================================================\n",
    "BASE_DIR = Path(\"/home/battistini/exp\")  # Local Linux\n",
    "# BASE_DIR = Path(\"/content/oxe\")  # Colab\n",
    "# BASE_DIR = Path(\"C:/Users/YourName/Documents/oxe-bt-pipeline\")  # Windows\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"output_smolvlm2_lora\"\n",
    "DATA_DIR = BASE_DIR / \"private_datasets\" / \"oxe_vlm_jsonl\"\n",
    "\n",
    "model_cfg = ModelConfig(\n",
    "    model_id=\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\"\n",
    ")\n",
    "\n",
    "lora_cfg = LoRAConfig(\n",
    "    use_lora=True,\n",
    "    use_qlora=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,  # or 4*r for stability\n",
    ")\n",
    "\n",
    "train_cfg = TrainingConfig(\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    checkpoint_dir=None,  # Defaults to output_dir/ckpts\n",
    "    log_dir=None,  # Defaults to output_dir/tblogs\n",
    "    batch_size=1,\n",
    "    epochs=3,\n",
    "    lr=2e-4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    val_every=1,  # Validate every N epochs\n",
    "    val_every_opt_steps=0,  # Or validate every K optimizer steps\n",
    "    patience=2,  # Early stopping\n",
    "    save_every_epochs=1,\n",
    "    keep_last_k=3,\n",
    "    dropout_ratio=0.0,  # Instruction dropout for robustness\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "data_cfg = DataConfig(\n",
    "    train_jsonl=str(DATA_DIR / \"train\" / \"data.jsonl\"),\n",
    "    val_jsonl=str(DATA_DIR / \"val\" / \"data.jsonl\"),\n",
    ")\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Data: {DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587da36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Initialize W&B (optional)\n",
    "# ============================================================\n",
    "\n",
    "wandb.init(\n",
    "    project=\"smolvlm2-bt-generation\",\n",
    "    name=os.path.basename(train_cfg.output_dir.rstrip(\"/\")),\n",
    "    config={\n",
    "        \"model\": model_cfg.__dict__,\n",
    "        \"lora\": lora_cfg.__dict__,\n",
    "        \"training\": train_cfg.__dict__,\n",
    "    },\n",
    "    dir=train_cfg.output_dir,\n",
    ")\n",
    "\n",
    "print(\"✓ W&B initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bb85a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Set Seeds and Create Directories\n",
    "# ============================================================\n",
    "\n",
    "set_seeds(train_cfg.seed)\n",
    "safe_makedirs(train_cfg.output_dir)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111aef9d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Load Data\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load processor first (needed for collate function)\n",
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(model_cfg.model_id, trust_remote_code=True)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = VLMJsonlDataset(data_cfg.train_jsonl)\n",
    "val_ds = VLMJsonlDataset(data_cfg.val_jsonl) if data_cfg.val_jsonl else None\n",
    "\n",
    "print(f\"✓ Train samples: {len(train_ds)}\")\n",
    "if val_ds:\n",
    "    print(f\"✓ Val samples: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5b6ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Inspect a Sample (DEBUG)\n",
    "# ============================================================\n",
    "\n",
    "sample = train_ds[0]\n",
    "print(\"\\nSample structure:\")\n",
    "print(sample[\"messages\"])\n",
    "\n",
    "# Apply collate to see processed batch\n",
    "collate = make_collate_fn(processor, dropout_ratio=0.0)\n",
    "batch = collate([sample])\n",
    "\n",
    "print(\"\\nBatch keys:\", batch.keys())\n",
    "print(\"Input IDs shape:\", batch[\"input_ids\"].shape)\n",
    "print(\"Labels shape:\", batch[\"labels\"].shape)\n",
    "if \"pixel_values\" in batch:\n",
    "    print(\"Pixel values shape:\", batch[\"pixel_values\"].shape)\n",
    "\n",
    "# Decode to see tokenized text\n",
    "decoded = processor.tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=False)\n",
    "print(\"\\nDecoded input (first 500 chars):\")\n",
    "print(decoded[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dd558",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 7: Create DataLoaders\n",
    "# ============================================================\n",
    "\n",
    "collate_train = make_collate_fn(processor, dropout_ratio=train_cfg.dropout_ratio)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_train,\n",
    "    num_workers=train_cfg.num_workers,\n",
    "    pin_memory=(device == \"cuda\"),\n",
    ")\n",
    "\n",
    "val_loader = None\n",
    "if val_ds:\n",
    "    collate_val = make_collate_fn(processor, dropout_ratio=0.0)\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_val,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "        pin_memory=(device == \"cuda\"),\n",
    "    )\n",
    "\n",
    "print(\"✓ DataLoaders created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc28cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 8: Setup Model\n",
    "# ============================================================\n",
    "\n",
    "print(\"Setting up model...\")\n",
    "processor, model = setup_model_and_processor(model_cfg, lora_cfg, device)\n",
    "\n",
    "# Optional: resume from checkpoint\n",
    "if train_cfg.resume_from:\n",
    "    resume_path = train_cfg.resume_from\n",
    "    if resume_path == \"latest\":\n",
    "        ckpt_dir = train_cfg.checkpoint_dir or os.path.join(train_cfg.output_dir, \"ckpts\")\n",
    "        resume_path = os.path.join(ckpt_dir, \"latest\")\n",
    "    \n",
    "    # We'll handle optimizer/scheduler in trainer\n",
    "    from peft import PeftModel\n",
    "    if lora_cfg.use_lora or lora_cfg.use_qlora:\n",
    "        model = PeftModel.from_pretrained(model, resume_path, is_trainable=True)\n",
    "        print(f\"✓ Resumed adapters from {resume_path}\")\n",
    "\n",
    "print(\"✓ Model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb5ac4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 9: Create Trainer and Train\n",
    "# ============================================================\n",
    "\n",
    "trainer = VLMTrainer(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_config=train_cfg,\n",
    "    lora_config=lora_cfg,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer initialized\")\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "trainer.fit()\n",
    "\n",
    "print(\"✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b69e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 10: Quick Inference Test (DEBUG)\n",
    "# ============================================================\n",
    "\n",
    "from inference_core import generate_once\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_prompt = \"Pick up the red cube and place it in the blue box\"\n",
    "test_image = \"/path/to/test_image.jpg\"  # Update this\n",
    "\n",
    "xml = generate_once(\n",
    "    model, processor, device,\n",
    "    system_text=train_cfg.system_prompt if hasattr(train_cfg, 'system_prompt') else \"\",\n",
    "    prompt_text=test_prompt,\n",
    "    image_path=test_image,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated BehaviorTree:\")\n",
    "print(xml)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
