{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2e56f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Platform-agnostic path setup\n",
    "src_dir = Path.cwd().parent / \"src\"\n",
    "if not src_dir.exists():\n",
    "    src_dir = Path.cwd() / \"src\"\n",
    "sys.path.insert(0, str(src_dir.resolve()))\n",
    "\n",
    "from config import InferenceConfig\n",
    "from inference_core import load_model_and_processor, generate_once, DEFAULT_SYSTEM\n",
    "from utils import setup_logging\n",
    "\n",
    "import torch\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "print(\"✓ Imports loaded\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83e4cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Configuration\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# CHANGE THIS PATH FOR YOUR ENVIRONMENT\n",
    "# ============================================================\n",
    "ADAPTER_DIR = Path(\"/home/battistini/exp/output_smolvlm2_lora/best\")  # Local Linux\n",
    "# ADAPTER_DIR = Path(\"/content/oxe/outputs/exp1/best\")  # Colab\n",
    "# ADAPTER_DIR = Path(\"C:/Users/YourName/Documents/oxe-bt-pipeline/outputs/exp1/best\")  # Windows\n",
    "# ============================================================\n",
    "\n",
    "infer_cfg = InferenceConfig(\n",
    "    base_id=\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\",\n",
    "    adapter_dir=str(ADAPTER_DIR),\n",
    "    merged_dir=\"\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=1.0,\n",
    "    do_sample=False,\n",
    "    system_prompt=DEFAULT_SYSTEM,\n",
    ")\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Adapter: {ADAPTER_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663a1c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Load Model\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading model...\")\n",
    "device, processor, model = load_model_and_processor(infer_cfg)\n",
    "print(\"✓ Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e1f4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Single Generation\n",
    "# ============================================================\n",
    "\n",
    "prompt = \"Pick up the bread and place it on the plate\"\n",
    "image_path = \"/path/to/your/image.jpg\"\n",
    "video_path = None  # Or provide video path instead\n",
    "\n",
    "xml = generate_once(\n",
    "    model, processor, device,\n",
    "    system_text=infer_cfg.system_prompt,\n",
    "    prompt_text=prompt,\n",
    "    video_path=video_path,\n",
    "    image_path=image_path,\n",
    "    max_new_tokens=infer_cfg.max_new_tokens,\n",
    "    temperature=infer_cfg.temperature,\n",
    "    do_sample=infer_cfg.do_sample,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Generated BehaviorTree ===\")\n",
    "print(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4929a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Batch Evaluation (Optional)\n",
    "# ============================================================\n",
    "\n",
    "test_cases = [\n",
    "    {\"prompt\": \"grasp the object\", \"image\": \"/path/to/img1.jpg\"},\n",
    "    {\"prompt\": \"move to the left\", \"image\": \"/path/to/img2.jpg\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for case in test_cases:\n",
    "    xml = generate_once(\n",
    "        model, processor, device,\n",
    "        system_text=infer_cfg.system_prompt,\n",
    "        prompt_text=case[\"prompt\"],\n",
    "        image_path=case[\"image\"],\n",
    "        max_new_tokens=infer_cfg.max_new_tokens,\n",
    "    )\n",
    "    results.append({\"prompt\": case[\"prompt\"], \"output\": xml})\n",
    "    print(f\"\\nPrompt: {case['prompt']}\")\n",
    "    print(f\"Output:\\n{xml[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2584c37",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Interactive REPL (Optional)\n",
    "# ============================================================\n",
    "\n",
    "# Run this cell for interactive mode\n",
    "import sys\n",
    "\n",
    "current_system = infer_cfg.system_prompt\n",
    "current_video = None\n",
    "current_image = None\n",
    "\n",
    "print(\"REPL Mode - Commands: ::video, ::image, ::system, ::quit\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        prompt_input = input(\"\\nprompt> \").strip()\n",
    "        \n",
    "        if not prompt_input:\n",
    "            continue\n",
    "        \n",
    "        if prompt_input.startswith(\"::\"):\n",
    "            cmd, *args = prompt_input[2:].split(\" \", 1)\n",
    "            arg = args[0].strip() if args else \"\"\n",
    "            \n",
    "            if cmd == \"quit\":\n",
    "                break\n",
    "            elif cmd == \"video\":\n",
    "                current_video = arg or None\n",
    "                current_image = None\n",
    "                print(f\"OK: video -> {current_video}\")\n",
    "            elif cmd == \"image\":\n",
    "                current_image = arg or None\n",
    "                current_video = None\n",
    "                print(f\"OK: image -> {current_image}\")\n",
    "            elif cmd == \"system\":\n",
    "                current_system = arg if arg else input(\"new SYSTEM> \").strip()\n",
    "                print(\"OK: SYSTEM updated\")\n",
    "            else:\n",
    "                print(f\"Unknown command: {cmd}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate\n",
    "        xml = generate_once(\n",
    "            model, processor, device,\n",
    "            system_text=current_system,\n",
    "            prompt_text=prompt_input,\n",
    "            video_path=current_video,\n",
    "            image_path=current_image,\n",
    "            max_new_tokens=infer_cfg.max_new_tokens,\n",
    "            temperature=infer_cfg.temperature,\n",
    "            do_sample=infer_cfg.do_sample,\n",
    "        )\n",
    "        \n",
    "        print(\"\\n=== OUTPUT ===\")\n",
    "        print(xml)\n",
    "\n",
    "except (EOFError, KeyboardInterrupt):\n",
    "    print(\"\\nExiting REPL\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
